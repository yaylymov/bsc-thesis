@online{peele,
  author = {BuzzFeed},
  title  = {You Won't Believe What Obama Says In This Video!},
  year   = {2018},
  month  = {04},
  day    = {17},
  url    = {https://www.youtube.com/watch?v=cQ54GDm1eL0},
  note   = {Accessed: 21.05.2023}
}

@online{deeptomcruise,
  author = {Miles Fisher},
  title  = {How I Became the Fake Tom Cruise},
  year   = {2022},
  month  = {07},
  day    = {21},
  url    = {https://www.hollywoodreporter.com/feature/deepfake-tom-cruise-miles-fisher-1235182932/},
  note   = {Accessed: 21.05.2023}
}

@article{10.1145/3371409,
  author     = {Greengard, Samuel},
  title      = {Will Deepfakes Do Deep Damage?},
  year       = {2019},
  issue_date = {January 2020},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {63},
  number     = {1},
  issn       = {0001-0782},
  url        = {https://doi.org/10.1145/3371409},
  doi        = {10.1145/3371409},
  abstract   = {The ability to produce fake videos that appear amazingly real is here. Researchers are now developing ways to detect and prevent them.},
  journal    = {Commun. ACM},
  month      = {12},
  pages      = {17-19},
  numpages   = {3}
}

@online{bill-hader,
  author = {{Ctrl Shift Face}},
  title  = {Bill Hader impersonates Arnold Schwarzenegger [DeepFake]},
  year   = {2019},
  month  = {05},
  day    = {11},
  url    = {https://www.youtube.com/watch?v=bPhUhypV27w},
  note   = {Accessed: 13.07.2023}
}

@online{kaggle2020,
  author = {Kaggle},
  title  = {Deepfake Detection Challenge},
  year   = {2019},
  month  = {12},
  day    = {11},
  url    = {https://www.kaggle.com/competitions/deepfake-detection-challenge/},
  note   = {Accessed: 27.07.2023}
}

@online{emma-stone-faceswap,
  author = {Dailymotion},
  title  = {Faceswap Phaze-A - 256px Demo},
  year   = {2021},
  month  = {05},
  day    = {1},
  url    = {https://dai.ly/x810mot},
  note   = {Accessed: 05.08.2023}
}

@online{deepfakes-business-insider,
  author = {Dave Johnson and Alexander Johnson},
  title  = {What are deepfakes? How fake AI-powered audio and video warps our perception of reality},
  year   = {2023},
  month  = {06},
  day    = {15},
  url    = {https://www.businessinsider.com/guides/tech/what-is-deepfake},
  note   = {Accessed: 13.07.2023}
}

@online{partnershiponai,
  author = {Claire Leibowicz and Jonathan Stray and Emily Saltz},
  title  = {Manipulated Media Detection Requires More Than Tools: Community Insights on What's Needed},
  year   = {2020},
  month  = {07},
  day    = {13},
  url    = {https://partnershiponai.org/manipulated-media-detection-requires-more-than-tools-community-insights-on-whats-needed/},
  note   = {Accessed: 13.07.2023}
}

@online{autoencoders-what-is,
  author = {Oliver Goodwin},
  title  = {What is a Deepfake?},
  year   = {2022},
  month  = {05},
  day    = {03},
  url    = {https://synthesys.io/blog/what-is-deepfake/},
  note   = {Accessed: 13.08.2023}
}

@online{latent-space-medium,
  author = {Enoch Kan},
  title  = {What The Heck Are VAE-GANs?},
  year   = {2018},
  month  = {08},
  day    = {17},
  url    = {https://towardsdatascience.com/what-the-heck-are-vae-gans-17b86023588a},
  note   = {Accessed: 13.08.2023}
}

@online{autoencoders-image-alazucconi,
  author = {Alan Zucconi},
  title  = {Understanding the Technology Behind DeepFakes},
  year   = {2018},
  month  = {03},
  day    = {14},
  url    = {https://www.alanzucconi.com/2018/03/14/understanding-the-technology-behind-deepfakes/},
  note   = {Accessed: 13.08.2023}
}

@online{fakeapp-app,
  author = {Lauriane Guilloux},
  title  = {Swap faces on videos by means of AI},
  year   = {2019},
  month  = {03},
  day    = {07},
  url    = {https://www.malavida.com/en/soft/fakeapp/},
  note   = {Accessed: 13.08.2023}
}

@online{ibm-machine-learning,
  author = {Julianna Delua},
  title  = {Supervised vs. Unsupervised Learning: What's the Difference?},
  year   = {2021},
  month  = {03},
  day    = {12},
  url    = {https://www.ibm.com/blog/supervised-vs-unsupervised-learning/},
  note   = {Accessed: 13.08.2023}
}

@online{supervised-unsupervised,
  author = {Pragati Baheti},
  title  = {Supervised and Unsupervised Learning [Differences \& Examples]},
  year   = {2021},
  month  = {10},
  day    = {01},
  url    = {https://www.v7labs.com/blog/supervised-vs-unsupervised-learning},
  note   = {Accessed: 13.08.2023}
}

@online{generative-discriminative,
  author = {Ajitesh Kumar},
  title  = {Generative vs Discriminative Models: Examples},
  year   = {2023},
  month  = {03},
  day    = {17},
  url    = {https://vitalflux.com/generative-vs-discriminative-models-examples/},
  note   = {Accessed: 13.08.2023}
}

@online{generative-discriminative2,
  author = {Chirag Goyal},
  title  = {2023's Best Guide to Discriminative \& Generative Machine Learning Models},
  year   = {2023},
  month  = {06},
  day    = {12},
  url    = {https://www.analyticsvidhya.com/blog/2021/07/deep-understanding-of-discriminative-and-generative-models-in-machine-learning/#:~:text=In%20simple%20words%2C%20a%20discriminative,probability%20for%20a%20given%20example.},
  note   = {Accessed: 13.08.2023}
}

@online{labeled-data,
  author = {AWS Amazon},
  title  = {What is data labeling?},
  url    = {https://aws.amazon.com/sagemaker/data-labeling/what-is-data-labeling/},
  note   = {Accessed: 13.08.2023}
}

@inproceedings{Bulat_2017,
  doi       = {10.1109/iccv.2017.116},
  url       = {https://doi.org/10.1109%2Ficcv.2017.116},
  year      = {2017},
  month     = {10},
  publisher = {{IEEE}},
  author    = {Adrian Bulat and Georgios Tzimiropoulos},
  title     = {How Far are We from Solving the 2D \& 3D Face Alignment Problem? (and a Dataset of 230,000 3D Facial Landmarks)},
  booktitle = {2017 {IEEE} International Conference on Computer Vision ({ICCV})}
}

@misc{iglovikov2018ternausnet,
  title         = {TernausNet: U-Net with VGG11 Encoder Pre-Trained on ImageNet for Image Segmentation},
  author        = {Vladimir Iglovikov and Alexey Shvets},
  year          = {2018},
  eprint        = {1801.05746},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@online{sd-hugging-face,
  author = {huggingface.co},
  title  = {Diffuse The Rest - a Hugging Face Space by huggingface},
  url    = {https://huggingface.co/spaces/huggingface-projects/diffuse-the-rest},
  note   = {Accessed: 13.08.2023}
}

@online{labeled-data,
  author = {AWS Amazon},
  title  = {What is data labeling?},
  url    = {https://aws.amazon.com/sagemaker/data-labeling/what-is-data-labeling/},
  note   = {Accessed: 13.08.2023}
}

@article{s22124556,
  author         = {Shahzad, Hina Fatima and Rustam, Furqan and Flores, Emmanuel Soriano and Luís Vidal Mazón, Juan and de la Torre Diez, Isabel and Ashraf, Imran},
  title          = {A Review of Image Processing Techniques for Deepfakes},
  journal        = {Sensors},
  volume         = {22},
  year           = {2022},
  number         = {12},
  article-number = {4556},
  url            = {https://www.mdpi.com/1424-8220/22/12/4556},
  pubmedid       = {35746333},
  issn           = {1424-8220},
  doi            = {10.3390/s22124556}
}

 @misc{enwiki:1170192786,
  author = {{Wikipedia contributors}},
  title  = {Deepfake --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2023},
  url    = {https://en.wikipedia.org/w/index.php?title=Deepfake&oldid=1170192786},
  note   = {[Online; accessed 13-August-2023]}
}

  @misc{enwiki:1169846514,
  author = {{Wikipedia contributors}},
  title  = {Generative adversarial network --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2023},
  url    = {https://en.wikipedia.org/w/index.php?title=Generative_adversarial_network&oldid=1169846514},
  note   = {[Online; accessed 13-August-2023]}
}

@misc{salimans2016improved,
  title         = {Improved Techniques for Training GANs},
  author        = {Tim Salimans and Ian Goodfellow and Wojciech Zaremba and Vicki Cheung and Alec Radford and Xi Chen},
  year          = {2016},
  eprint        = {1606.03498},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{pix2pix2017,
  title   = {Image-to-Image Translation with Conditional Adversarial Networks},
  author  = {Isola, Phillip and Zhu, Jun-Yan and Zhou, Tinghui and Efros, Alexei A},
  journal = {CVPR},
  year    = {2017}
}

@misc{ho2016generative,
  title         = {Generative Adversarial Imitation Learning},
  author        = {Jonathan Ho and Stefano Ermon},
  year          = {2016},
  eprint        = {1606.03476},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@online{gans-versions,
  author = {Gaudenz Boesch},
  title  = {Guide to Generative Adversarial Networks (GANs) in 2023},
  year   = {2023},
  url    = {https://viso.ai/deep-learning/generative-adversarial-networks-gan/},
  note   = {Accessed: 13.08.2023}
}

@misc{mirza2014conditional,
  title         = {Conditional Generative Adversarial Nets},
  author        = {Mehdi Mirza and Simon Osindero},
  year          = {2014},
  eprint        = {1411.1784},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{yi2018dualgan,
  title         = {DualGAN: Unsupervised Dual Learning for Image-to-Image Translation},
  author        = {Zili Yi and Hao Zhang and Ping Tan and Minglun Gong},
  year          = {2018},
  eprint        = {1704.02510},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{zhang2017stackgan,
  title         = {StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks},
  author        = {Han Zhang and Tao Xu and Hongsheng Li and Shaoting Zhang and Xiaogang Wang and Xiaolei Huang and Dimitris Metaxas},
  year          = {2017},
  eprint        = {1612.03242},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{zhu2020unpaired,
  title         = {Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks},
  author        = {Jun-Yan Zhu and Taesung Park and Phillip Isola and Alexei A. Efros},
  year          = {2020},
  eprint        = {1703.10593},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{ledig2017photorealistic,
  title         = {Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network},
  author        = {Christian Ledig and Lucas Theis and Ferenc Huszar and Jose Caballero and Andrew Cunningham and Alejandro Acosta and Andrew Aitken and Alykhan Tejani and Johannes Totz and Zehan Wang and Wenzhe Shi},
  year          = {2017},
  eprint        = {1609.04802},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{radford2016unsupervised,
  title         = {Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks},
  author        = {Alec Radford and Luke Metz and Soumith Chintala},
  year          = {2016},
  eprint        = {1511.06434},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{zhang2019selfattention,
  title         = {Self-Attention Generative Adversarial Networks},
  author        = {Han Zhang and Ian Goodfellow and Dimitris Metaxas and Augustus Odena},
  year          = {2019},
  eprint        = {1805.08318},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

@online{vae-gan,
  author = {Georgios Nanos},
  title  = {VAE Vs. GAN For Image Generation},
  year   = {2023},
  month  = {03},
  day    = {16},
  url    = {https://www.baeldung.com/cs/vae-vs-gan-image-generation},
  note   = {Accessed: 13.08.2023}
}

  @misc{enwiki:1169655673,
  author = {{Wikipedia contributors}},
  title  = {Latent space --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2023},
  url    = {https://en.wikipedia.org/w/index.php?title=Latent_space&oldid=1169655673},
  note   = {[Online; accessed 13-August-2023]}
}

@online{faceswap,
  author = {Deepfakes},
  title  = {FaceSwap},
  url    = {https://github.com/deepfakes/faceswap}
}

@online{faceapp-app,
  author = {FaceApp Technology Limited},
  title  = {AceApp},
  url    = {https://www.faceapp.com/}
}

@online{stable-diffusion,
  author = {stability.ai},
  title  = {Stable Diffusion},
  url    = {https://stability.ai/stablediffusion}
}

@misc{perov2021deepfacelab,
  title         = {DeepFaceLab: Integrated, flexible and extensible face-swapping framework},
  author        = {Ivan Perov and Daiheng Gao and Nikolay Chervoniy and Kunlin Liu and Sugasa Marangonda and Chris Umé and Mr. Dpfks and Carl Shift Facenheim and Luis RP and Jian Jiang and Sheng Zhang and Pingyu Wu and Bo Zhou and Weiming Zhang},
  year          = {2021},
  eprint        = {2005.05535},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{deepfakes-thesis,
  title  = {Detecting Deepfakes and Forged Videos Using Deep Learning},
  author = {Emil Johansson},
  year   = {2020},
  url    = {https://www.lunduniversity.lu.se/lup/publication/9019746},
  note   = {Accessed: 13.08.2023}
}

@inproceedings{Korshunova_2017_ICCV,
  author    = {Korshunova, Iryna and Shi, Wenzhe and Dambre, Joni and Theis, Lucas},
  title     = {Fast Face-Swap Using Convolutional Neural Networks},
  booktitle = {Proceedings of the IEEE International Conference on Computer Vision (ICCV)},
  month     = {10},
  year      = {2017}
}

@misc{ho2020denoising,
  title         = {Denoising Diffusion Probabilistic Models},
  author        = {Jonathan Ho and Ajay Jain and Pieter Abbeel},
  year          = {2020},
  eprint        = {2006.11239},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@inproceedings{10.1145/3588015.3589842,
  author    = {Kurzhals, Kuno},
  title     = {Privacy in Eye Tracking Research with Stable Diffusion},
  year      = {2023},
  isbn      = {9798400701504},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3588015.3589842},
  doi       = {10.1145/3588015.3589842},
  abstract  = {Image-generative models take textual prompts as input and generate almost arbitrary image content based on the underlying training data. This technology is rapidly developing and produces better results with each new generation of trained models. Apart from the application to create artwork, we see potential in deploying such models for eye-tracking research with respect to anonymizing content in visual stimuli. One feature of such models is the ability to take an image as input and adjust content according to a prompt. Hence, privacy-preserving visualization of stimuli can be achieved for static images and videos by slightly adjusting content to anonymize persons, text, and other sensible sources. In this work, we will discuss how this process can be applied to the presentation and dissemination of results with respect to privacy issues resulting from eye-tracking experiments.},
  booktitle = {Proceedings of the 2023 Symposium on Eye Tracking Research and Applications},
  articleno = {70},
  numpages  = {7},
  keywords  = {visualization, neural networks, privacy, stable diffusion, eye tracking, anonymization},
  location  = {Tubingen, Germany},
  series    = {ETRA '23}
}

@inproceedings{9897972,
  author    = {Jia, Shan and Li, Xin and Lyu, Siwei},
  booktitle = {2022 IEEE International Conference on Image Processing (ICIP)},
  title     = {Model Attribution of Face-Swap Deepfake Videos},
  year      = {2022},
  volume    = {},
  number    = {},
  pages     = {2356-2360},
  doi       = {10.1109/ICIP46576.2022.9897972}
}

@inproceedings{10.1117/12.2631297,
  author       = {Feiyu Jia and Sihan Yang},
  title        = {{Video face swap with DeepFaceLab}},
  volume       = {12168},
  booktitle    = {International Conference on Computer Graphics, Artificial Intelligence, and Data Processing (ICCAID 2021)},
  editor       = {Feng Wu and Jinping Liu and Yanping Chen},
  organization = {International Society for Optics and Photonics},
  publisher    = {SPIE},
  pages        = {121681H},
  keywords     = {Deep learning, computer vision, DeepFaceLab, SAEHD, Face swap},
  year         = {2022},
  doi          = {10.1117/12.2631297},
  url          = {https://doi.org/10.1117/12.2631297}
}

@misc{rombach2022highresolution,
  title         = {High-Resolution Image Synthesis with Latent Diffusion Models},
  author        = {Robin Rombach and Andreas Blattmann and Dominik Lorenz and Patrick Esser and Björn Ommer},
  year          = {2022},
  eprint        = {2112.10752},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

  @misc{enwiki:1164523541,
  author = {{Wikipedia contributors}},
  title  = {Inpainting --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2023},
  url    = {https://en.wikipedia.org/w/index.php?title=Inpainting\&oldid=1164523541},
  note   = {[Online; accessed 14-August-2023]}
}

 @misc{enwiki:1169859793,
  author = {{Wikipedia contributors}},
  title  = {Stable Diffusion --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2023},
  url    = {https://en.wikipedia.org/w/index.php?title=Stable_Diffusion&oldid=1169859793},
  note   = {[Online; accessed 14-August-2023]}
}

@online{sifted-2020,
  author = {Tim Smith},
  title  = {Leaked deck raises questions over Stability AI's Series A pitch to investors},
  year   = {2023},
  month  = {04},
  day    = {21},
  url    = {https://sifted.eu/articles/stability-ai-fundraise-leak},
  note   = {Accessed: 13.08.2023}
}

@online{sd-lmu,
  author = {Ludwig Maximilian University of Munich},
  title  = {Revolutionizing image generation by AI: Turning text into images},
  year   = {2022},
  month  = {09},
  day    = {01},
  url    = {https://www.lmu.de/en/newsroom/news-overview/news/revolutionizing-image-generation-by-ai-turning-text-into-images.html},
  note   = {Accessed: 13.08.2023}
}

@online{stabilityai,
  author = {stability.ai},
  title  = {Stable Diffusion Launch Announcement},
  year   = {2022},
  month  = {08},
  day    = {10},
  url    = {https://stability.ai/blog/stable-diffusion-announcement},
  note   = {Accessed: 13.08.2023}
}

@online{sd-github,
  author = {CompVis},
  title  = {Stable Diffusion Repository on GitHub},
  url    = {https://github.com/CompVis/stable-diffusion},
  note   = {Accessed: 13.08.2023}
}

@online{dall-e,
  author = {OpenAI},
  title  = {DALL·E 2 is an AI system that can create realistic images and art from a description in natural language.},
  url    = {https://openai.com/dall-e-2},
  note   = {Accessed: 13.08.2023}
}

@online{midjourney,
  author = {Midjourney Inc.},
  title  = {Midjourney},
  url    = {https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F},
  note   = {Accessed: 13.08.2023}
}

@online{sd-theverge,
  author = {James Vincent},
  title  = {Anyone can use this AI art generator — that's the risk},
  year   = {2022},
  month  = {09},
  day    = {15},
  url    = {https://www.theverge.com/2022/9/15/23340673/ai-image-generation-stable-diffusion-explained-ethics-copyright-data},
  note   = {Accessed: 13.08.2023}
}

 @misc{enwiki:1169139226,
  author = {{Wikipedia contributors}},
  title  = {UV mapping --- {Wikipedia}{,} The Free Encyclopedia},
  year   = {2023},
  url    = {https://en.wikipedia.org/w/index.php?title=UV_mapping&oldid=1169139226},
  note   = {[Online; accessed 14-August-2023]}
}

@misc{thies2020face2face,
  title         = {Face2Face: Real-time Face Capture and Reenactment of RGB Videos},
  author        = {Justus Thies and Michael Zollhöfer and Marc Stamminger and Christian Theobalt and Matthias Nießner},
  year          = {2020},
  eprint        = {2007.14808},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{warzel2019faceapp,
  title   = {Faceapp shows we care about privacy but don’t understand it},
  author  = {Warzel, Charlie},
  journal = {New York Times},
  year    = {2019}
}

@article{wirth2023interface,
  title   = {Interface Experiments: FaceApp as Everyday AI},
  author  = {Wirth, Sabine},
  journal = {Interface Critique},
  number  = {4},
  year    = {2023}
}

@article{faceapp-article1,
  author  = {Offert, Fabian and Bell, Peter},
  year    = {2021},
  month   = {12},
  pages   = {1-12},
  title   = {Perceptual bias and technical metapictures: critical machine vision as a humanities challenge},
  volume  = {36},
  journal = {AI \& SOCIETY},
  doi     = {10.1007/s00146-020-01058-z}
}

@online{faceapp-medium,
  author = {Debojyoti Chakraborty},
  title  = {IN DEPTH OF Faceapp},
  year   = {2020},
  month  = {04},
  day    = {16},
  url    = {https://medium.com/analytics-vidhya/in-depth-of-faceapp-a08be9fe86f6},
  note   = {Accessed: 14.08.2023}
}

@online{faceapp-article2,
  author = {Devin Pickell},
  title  = {What Is FaceApp? The Technology Behind This AI-Enabled Mobile App},
  year   = {2019},
  month  = {07},
  day    = {17},
  url    = {https://learn.g2.com/faceapp},
  note   = {Accessed: 14.08.2023}
}

@article{MUSTAK2023113368,
  title   = {Deepfakes: Deceptions, mitigations, and opportunities},
  journal = {Journal of Business Research},
  volume  = {154},
  pages   = {113368},
  year    = {2023},
  issn    = {0148-2963},
  doi     = {https://doi.org/10.1016/j.jbusres.2022.113368},
  url     = {https://www.sciencedirect.com/science/article/pii/S0148296322008335},
  author  = {Mekhail Mustak and Joni Salminen and Matti Mäntymäki and Arafat Rahman and Yogesh K. Dwivedi}
}

@online{forbes-2020,
  author = {Rob Toews},
  title  = {Deepfakes Are Going To Wreak Havoc On Society. We Are Not Prepared},
  year   = {2020},
  month  = {05},
  day    = {25},
  url    = {https://www.forbes.com/sites/robtoews/2020/05/25/deepfakes-are-going-to-wreak-havoc-on-society-we-are-not-prepared/?sh=4b68fb7a7494},
  note   = {Accessed: 12.08.2023}
}

@online{guardian-2019,
  author = {Simon Parkin},
  title  = {The rise of the deepfake and threat to democracy},
  year   = {2019},
  month  = {06},
  day    = {22},
  url    = {https://www.theguardian.com/technology/ng-interactive/2019/jun/22/the-rise-of-the-deepfake-and-the-threat-to-democracy},
  note   = {Accessed: 12.08.2023}
}

@article{albahar2019deepfakes,
  title     = {Deepfakes: Threats and countermeasures systematic review},
  author    = {Albahar, Marwan and Almalki, Jameel},
  journal   = {Journal of Theoretical and Applied Information Technology},
  volume    = {97},
  number    = {22},
  pages     = {3242--3250},
  year      = {2019},
  publisher = {Little Lion Scientific}
}

@inproceedings{Gardiner2019FacialRS,
  title  = {Facial re-enactment, speech synthesis and the rise of the Deepfake},
  author = {Nicholas Gardiner},
  year   = {2019},
  url    = {https://api.semanticscholar.org/CorpusID:132624704}
}

@online{deeptomcruise-article,
  author = {Rachel Metz},
  title  = {How a deepfake Tom Cruise on TikTok turned into a very real AI company},
  year   = {2021},
  month  = {08},
  day    = {06},
  url    = {https://edition.cnn.com/2021/08/06/tech/tom-cruise-deepfake-tiktok-company/index.html},
  note   = {Accessed: 12.08.2023}
}

@article{Nguyen_2022,
  doi       = {10.1016/j.cviu.2022.103525},
  url       = {https://doi.org/10.1016%2Fj.cviu.2022.103525},
  year      = {2022},
  month     = {10},
  publisher = {Elsevier {BV}},
  volume    = {223},
  pages     = {103525},
  author    = {Thanh Thi Nguyen and Quoc Viet Hung Nguyen and Dung Tien Nguyen and Duc Thanh Nguyen and Thien Huynh-The and Saeid Nahavandi and Thanh Tam Nguyen and Quoc-Viet Pham and Cuong M. Nguyen},
  title     = {Deep learning for deepfakes creation and detection: A survey},
  journal   = {Computer Vision and Image Understanding}
}

@article{10.1145/3425780,
  author     = {Mirsky, Yisroel and Lee, Wenke},
  title      = {The Creation and Detection of Deepfakes: A Survey},
  year       = {2021},
  issue_date = {January 2022},
  publisher  = {Association for Computing Machinery},
  address    = {New York, NY, USA},
  volume     = {54},
  number     = {1},
  issn       = {0360-0300},
  url        = {https://doi.org/10.1145/3425780},
  doi        = {10.1145/3425780},
  abstract   = {Generative deep learning algorithms have progressed to a point where it is difficult to tell the difference between what is real and what is fake. In 2018, it was discovered how easy it is to use this technology for unethical and malicious applications, such as the spread of misinformation, impersonation of political leaders, and the defamation of innocent individuals. Since then, these “deepfakes” have advanced significantly.In this article, we explore the creation and detection of deepfakes and provide an in-depth view as to how these architectures work. The purpose of this survey is to provide the reader with a deeper understanding of (1) how deepfakes are created and detected, (2) the current trends and advancements in this domain, (3) the shortcomings of the current defense solutions, and (4) the areas that require further research and attention.},
  journal    = {ACM Comput. Surv.},
  month      = {01},
  articleno  = {7},
  numpages   = {41},
  keywords   = {social engineering, impersonation, replacement, Deepfake, generative AI, deep fake, reenactment, face swap}
}

@inproceedings{10.1145/3491102.3517446,
  author    = {Gamage, Dilrukshi and Ghasiya, Piyush and Bonagiri, Vamshi and Whiting, Mark E. and Sasahara, Kazutoshi},
  title     = {Are Deepfakes Concerning? Analyzing Conversations of Deepfakes on Reddit and Exploring Societal Implications},
  year      = {2022},
  isbn      = {9781450391573},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3491102.3517446},
  doi       = {10.1145/3491102.3517446},
  abstract  = {Deepfakes are synthetic content generated using advanced deep learning and AI technologies. The advancement of technology has created opportunities for anyone to create and share deepfakes much easier. This may lead to societal concerns based on how communities engage with it. However, there is limited research available to understand how communities perceive deepfakes. We examined deepfake conversations on Reddit from 2018 to 2021—including major topics and their temporal changes as well as implications of these conversations. Using a mixed-method approach—topic modeling and qualitative coding, we found 6,638 posts and 86,425 comments discussing concerns of the believable nature of deepfakes and how platforms moderate them. We also found Reddit conversations to be pro-deepfake and building a community that supports creating and sharing deepfake artifacts and building a marketplace regardless of the consequences. Possible implications derived from qualitative codes indicate that deepfake conversations raise societal concerns. We propose that there are implications for Human Computer Interaction (HCI) to mitigate the harm created from deepfakes.},
  booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  articleno = {103},
  numpages  = {19},
  keywords  = {topic modeling, deepfake, societal implication, content analysis},
  location  = {New Orleans, LA, USA},
  series    = {CHI '22}
}

@inproceedings{10.1145/3543873.3587581,
  author    = {Mehta, Pulak and Jagatap, Gauri and Gallagher, Kevin and Timmerman, Brian and Deb, Progga and Garg, Siddharth and Greenstadt, Rachel and Dolan-Gavitt, Brendan},
  title     = {Can Deepfakes Be Created on a Whim?},
  year      = {2023},
  isbn      = {9781450394192},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3543873.3587581},
  doi       = {10.1145/3543873.3587581},
  abstract  = {Recent advancements in machine learning and computer vision have led to the proliferation of Deepfakes. As technology democratizes over time, there is an increasing fear that novice users can create Deepfakes, to discredit others and undermine public discourse. In this paper, we conduct user studies to understand whether participants with advanced computer skills and varying level of computer science expertise can create Deepfakes of a person saying a target statement using limited media files. We conduct two studies; in the first study (n = 39) participants try creating a target Deepfake in a constrained time frame using any tool they desire. In the second study (n = 29) participants use pre-specified deep learning based tools to create the same Deepfake. We find that for the first study, of the participants successfully created complete Deepfakes with audio and video, whereas for the second user study, of the participants were successful in stitching target speech to the target video. We further use Deepfake detection software tools as well as human examiner-based analysis, to classify the successfully generated Deepfake outputs as fake, suspicious, or real. The software detector classified of the Deepfakes as fake, whereas the human examiners classified of the videos as fake. We conclude that creating Deepfakes is a simple enough task for a novice user given adequate tools and time; however, the resulting Deepfakes are not sufficiently real-looking and are unable to completely fool detection software as well as human examiners.},
  booktitle = {Companion Proceedings of the ACM Web Conference 2023},
  pages     = {1324–1334},
  numpages  = {11},
  keywords  = {deepfakes, generative models, video synthesis},
  location  = {Austin, TX, USA},
  series    = {WWW '23 Companion}
}

@inproceedings{Agarwal_2021_CVPR,
  author    = {Agarwal, Shruti and Farid, Hany},
  title     = {Detecting Deep-Fake Videos From Aural and Oral Dynamics},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  month     = {06},
  year      = {2021},
  pages     = {981-989}
}

@article{belive-or-not,
  author  = {Youngah, Lee and Huang, Kuo-Ting and Blom, Robin and Schriner, Rebecca and Ciccarelli, Carl},
  year    = {2021},
  month   = {02},
  pages   = {},
  title   = {To Believe or Not to Believe: Framing Analysis of Content and Audience Response of Top 10 Deepfake Videos on YouTube},
  volume  = {24},
  journal = {Cyberpsychology, Behavior, and Social Networking},
  doi     = {10.1089/cyber.2020.0176}
}

@misc{goodfellow2014generative,
  title         = {Generative Adversarial Networks},
  author        = {Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio},
  year          = {2014},
  eprint        = {1406.2661},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

@misc{brock2019large,
  title         = {Large Scale GAN Training for High Fidelity Natural Image Synthesis},
  author        = {Andrew Brock and Jeff Donahue and Karen Simonyan},
  year          = {2019},
  eprint        = {1809.11096},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{doi:10.1126/science.1127647,
  author   = {G. E. Hinton  and R. R. Salakhutdinov },
  title    = {Reducing the Dimensionality of Data with Neural Networks},
  journal  = {Science},
  volume   = {313},
  number   = {5786},
  pages    = {504-507},
  year     = {2006},
  doi      = {10.1126/science.1127647},
  url      = {https://www.science.org/doi/abs/10.1126/science.1127647},
  eprint   = {https://www.science.org/doi/pdf/10.1126/science.1127647},
  abstract = {High-dimensional data can be converted to low-dimensional 
              codes by training a multilayer neural network with a small central 
              layer to reconstruct high-dimensional input vectors. Gradient descent 
              can be used for fine-tuning the weights in such “autoencoder” networks, 
              but this works well only if the initial weights are close to a good solution. 
              We describe an effective way of initializing the weights that allows deep 
              autoencoder networks to learn low-dimensional codes that work much better 
              than principal components analysis as a tool to reduce the dimensionality 
              of data.}
}

@misc{simonyan2015deep,
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author        = {Karen Simonyan and Andrew Zisserman},
  year          = {2015},
  eprint        = {1409.1556},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{10.1145/3297156.3297210,
  author    = {Guo, Yanzong and He, Wangpeng and Zhu, Juanjuan and Li, Cheng},
  title     = {A Light Autoencoder Networks for Face Swapping},
  year      = {2018},
  isbn      = {9781450366069},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3297156.3297210},
  doi       = {10.1145/3297156.3297210},
  abstract  = {Face swapping in images is a process where an input identity is transformed into a target identity while preserving the former's facial expression, pose and lighting. In this paper, a new face swap method using autoencoder networks is investigated, which can capture the two different image sets to be trained. The images from two sets are unstructured collection of people's photographs. This approach is enabled by framing the face swapping problem in terms of style transfer, where the goal is to render an image in the style of another one. We design a new autoencoder network that enables the processing to produce photorealistic results. Moreover, in low resolution video, the proposed method can achieve face swap by combining autoencoder network with pre- and post-processing steps.},
  booktitle = {Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence},
  pages     = {459–462},
  numpages  = {4},
  keywords  = {computer vision, deep learning, autoencoder, machine learning},
  location  = {Shenzhen, China},
  series    = {CSAI '18}
}

@misc{kingma2022autoencoding,
  title         = {Auto-Encoding Variational Bayes},
  author        = {Diederik P Kingma and Max Welling},
  year          = {2022},
  eprint        = {1312.6114},
  archiveprefix = {arXiv},
  primaryclass  = {stat.ML}
}

@inproceedings{roessler2019faceforensicspp,
  author    = {Andreas R\"ossler and Davide Cozzolino and Luisa Verdoliva and Christian Riess and Justus Thies and Matthias Nie{\ss}ner},
  title     = {Face{F}orensics++: Learning to Detect Manipulated Facial Images},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year      = {2019}
}

@misc{wu2022unifying,
  title         = {Unifying Diffusion Models' Latent Space, with Applications to CycleDiffusion and Guidance},
  author        = {Chen Henry Wu and Fernando De la Torre},
  year          = {2022},
  eprint        = {2210.05559},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{faceapp,
  author = {Neyaz, Ashar and Kumar, Avinash and Krishnan, Sundar and Placker, Jessica and Liu, Qingzhong},
  year   = {2020},
  month  = {06},
  pages  = {},
  title  = {Security, Privacy and Steganographic Analysis of FaceApp and TikTok}
}

@misc{thies2019deferred,
  title         = {Deferred Neural Rendering: Image Synthesis using Neural Textures},
  author        = {Justus Thies and Michael Zollhöfer and Matthias Nießner},
  year          = {2019},
  eprint        = {1904.12356},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@article{chesney2019deep,
  title     = {Deep fakes: A looming challenge for privacy, democracy, and national security},
  author    = {Chesney, Bobby and Citron, Danielle},
  journal   = {Calif. L. Rev.},
  volume    = {107},
  pages     = {1753},
  year      = {2019},
  publisher = {HeinOnline}
}

@article{doi:10.1177/2056305120903408,
  author   = {Cristian Vaccari and Andrew Chadwick},
  title    = {Deepfakes and Disinformation: Exploring the Impact of Synthetic Political Video on Deception, Uncertainty, and Trust in News},
  journal  = {Social Media + Society},
  volume   = {6},
  number   = {1},
  pages    = {2056305120903408},
  year     = {2020},
  doi      = {10.1177/2056305120903408},
  url      = {https://doi.org/10.1177/2056305120903408},
  eprint   = {https://doi.org/10.1177/2056305120903408},
  abstract = {Artificial Intelligence (AI) now enables the mass 
              creation of what have become known as “deepfakes”: synthetic 
              videos that closely resemble real videos. Integrating theories 
              about the power of visual communication and the role played by 
              uncertainty in undermining trust in public discourse, we explain 
              the likely contribution of deepfakes to online disinformation. 
              Administering novel experimental treatments to a large representative 
              sample of the United Kingdom population allowed us to compare 
              people's evaluations of deepfakes. We find that people are more 
              likely to feel uncertain than to be misled by deepfakes, but 
              this resulting uncertainty, in turn, reduces trust in news on 
              social media. We conclude that deepfakes may contribute toward 
              generalized indeterminacy and cynicism, further intensifying 
              recent challenges to online civic culture in democratic societies.}
}

@inproceedings{Agarwal_2019_CVPR_Workshops,
  author    = {Agarwal, Shruti and Farid, Hany and Gu, Yuming and He, Mingming and Nagano, Koki and Li, Hao},
  title     = {Protecting World Leaders Against Deep Fakes},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops},
  month     = {06},
  year      = {2019}
} 

@misc{durall2020unmasking,
  title         = {Unmasking DeepFakes with simple Features},
  author        = {Ricard Durall and Margret Keuper and Franz-Josef Pfreundt and Janis Keuper},
  year          = {2020},
  eprint        = {1911.00686},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{nguyen2018capsuleforensics,
  title         = {Capsule-Forensics: Using Capsule Networks to Detect Forged Images and Videos},
  author        = {Huy H. Nguyen and Junichi Yamagishi and Isao Echizen},
  year          = {2018},
  eprint        = {1810.11215},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{cozzolino2017recasting,
  title         = {Recasting Residual-based Local Descriptors as Convolutional Neural Networks: an Application to Image Forgery Detection},
  author        = {Davide Cozzolino and Giovanni Poggi and Luisa Verdoliva},
  year          = {2017},
  eprint        = {1703.04615},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{li2018ictu,
  title         = {In Ictu Oculi: Exposing AI Generated Fake Face Videos by Detecting Eye Blinking},
  author        = {Yuezun Li and Ming-Ching Chang and Siwei Lyu},
  year          = {2018},
  eprint        = {1806.02877},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{dolhansky2020deepfake,
  title         = {The DeepFake Detection Challenge (DFDC) Dataset},
  author        = {Brian Dolhansky and Joanna Bitton and Ben Pflaum and Jikuo Lu and Russ Howes and Menglin Wang and Cristian Canton Ferrer},
  year          = {2020},
  eprint        = {2006.07397},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{Zhou_2021_CVPR,
  author    = {Zhou, Tianfei and Wang, Wenguan and Liang, Zhiyuan and Shen, Jianbing},
  title     = {Face Forensics in the Wild},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  month     = {06},
  year      = {2021},
  pages     = {5778-5788}
}


@inproceedings{ltnghia-ICCV2021,
  title     = {OpenForensics: Large-Scale Challenging Dataset For Multi-Face Forgery Detection And Segmentation In-The-Wild},
  author    = {Trung-Nghia Le and Huy H. Nguyen and Junichi Yamagishi and Isao Echizen},
  booktitle = {International Conference on Computer Vision},
  year      = {2021}
}

@misc{tan2020efficientnet,
  title         = {EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks},
  author        = {Mingxing Tan and Quoc V. Le},
  year          = {2020},
  eprint        = {1905.11946},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@misc{xie2020selftraining,
  title         = {Self-training with Noisy Student improves ImageNet classification},
  author        = {Qizhe Xie and Minh-Thang Luong and Eduard Hovy and Quoc V. Le},
  year          = {2020},
  eprint        = {1911.04252},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG}
}

@article{ILSVRC15,
  author  = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
  title   = {{ImageNet Large Scale Visual Recognition Challenge}},
  year    = {2015},
  journal = {International Journal of Computer Vision (IJCV)},
  doi     = {10.1007/s11263-015-0816-y},
  volume  = {115},
  number  = {3},
  pages   = {211-252}
}

@misc{cubuk2019autoaugment,
  title         = {AutoAugment: Learning Augmentation Policies from Data},
  author        = {Ekin D. Cubuk and Barret Zoph and Dandelion Mane and Vijay Vasudevan and Quoc V. Le},
  year          = {2019},
  eprint        = {1805.09501},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@misc{zhong2017random,
  title         = {Random Erasing Data Augmentation},
  author        = {Zhun Zhong and Liang Zheng and Guoliang Kang and Shaozi Li and Yi Yang},
  year          = {2017},
  eprint        = {1708.04896},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@online{facetorch,
  author = {Tomáš Gajarský},
  title  = {Facetorch User Guide},
  year   = {2022},
  month  = {09},
  day    = {02},
  url    = {https://medium.com/@gajarsky.tomas/facetorch-user-guide-a0e9fd2a5552},
  note   = {Accessed: 29.07.2023}
}

@online{facetorch-documentation,
  author = {Tomáš Gajarský},
  title  = {Facetorch Documentation},
  year   = {2022},
  url    = {https://tomas-gajarsky.github.io/facetorch/facetorch/index.html},
  note   = {Accessed: 29.07.2023}
}

@online{facetorch-hugging-face,
  author = {Tomáš Gajarský},
  title  = {Facetorch Hugging Face instance},
  year   = {2022},
  url    = {https://huggingface.co/spaces/tomas-gajarsky/facetorch-app},
  note   = {Accessed: 29.07.2023}
}

@online{facetorch-google-colab,
  author = {Tomáš Gajarský},
  title  = {Facetorch Google Colab notebook},
  year   = {2022},
  url    = {https://colab.research.google.com/github/tomas-gajarsky/facetorch/blob/main/notebooks/facetorch_notebook_demo.ipynb},
  note   = {Accessed: 29.07.2023}
}

@online{ai-or-not,
  author = {Dunja Djudjic},
  title  = {BYE-BYE FAKE NEWS: THIS FREE TOOL SPOTS AI-GENERATED IMAGES IN A SECOND},
  year   = {2023},
  month  = {06},
  day    = {15},
  url    = {https://www.diyphotography.net/optic-tool-spots-ai-generated-images/},
  note   = {Accessed: 01.08.2023}
}

@online{motion-analysis,
  author = {{Motion Analysis}},
  title  = {Deepfake technology for entertainment: the pros and cons},
  year   = {2022},
  month  = {08},
  day    = {03},
  url    = {https://www.motionanalysis.com/biomechanics/deepfake-technology-for-entertainment-the-pros-and-cons/},
  note   = {Accessed: 02.08.2023}
}

@online{wipo-magazine,
  author = {Vejay Lalla and Adine Mitrani and Zach Harned},
  title  = {Artificial intelligence: deepfakes in the entertainment industry},
  year   = {2022},
  month  = {06},
  url    = {https://www.motionanalysis.com/biomechanics/deepfake-technology-for-entertainment-the-pros-and-cons/},
  note   = {Accessed: 02.08.2023}
}

@online{salvador-dali,
  author = {Emily White},
  title  = {Positive Implications Of Deepfake Technology In The Arts And Culture},
  year   = {2021},
  month  = {09},
  day    = {01},
  url    = {https://amt-lab.org/blog/2021/8/positive-implications-of-deepfake-technology-in-the-arts-and-culture},
  note   = {Accessed: 09.08.2023}
}

@online{salvador-dali2,
  author = {{Salvador Dalí Museum}},
  title  = {dalí lives: museum brings artist back to life with ai},
  year   = {2019},
  month  = {01},
  day    = {23},
  url    = {https://thedali.org/press-room/dali-lives-museum-brings-artists-back-to-life-with-ai/},
  note   = {Accessed: 09.08.2023}
}

@online{salvador-dali-youtube,
  author = {{The Dalí Museum}},
  title  = {Behind the Scenes, Dalí Lives},
  year   = {2019},
  month  = {05},
  day    = {08},
  url    = {https://www.youtube.com/watch?v=BIDaxl4xqJ4},
  note   = {Accessed: 09.08.2023}
}

@online{california,
  author = {Colin Lecher},
  title  = {California has banned political deepfakes during election season},
  year   = {2019},
  month  = {10},
  day    = {07},
  url    = {https://www.theverge.com/2019/10/7/20902884/california-deepfake-political-ban-election-2020},
  note   = {Accessed: 09.08.2023}
}

@online{spatial-domain,
  author = {Anshul Sachdev},
  title  = {Spatial and Frequency Domain — Image Processing},
  year   = {2019},
  month  = {10},
  day    = {02},
  url    = {https://medium.com/vithelper/spatial-and-frequency-domain-image-processing-83ffa3fc7cbc},
  note   = {Accessed: 10.08.2023}
}

@online{vice,
  author = {Nilesh Christopher},
  title  = {We've Just Seen the First Use of Deepfakes in an Indian Election Campaign},
  year   = {2020},
  month  = {02},
  day    = {18},
  url    = {https://www.vice.com/en/article/jgedjb/the-first-use-of-deepfakes-in-indian-election-by-bjp},
  note   = {Accessed: 10.08.2023}
}

@online{india,
  author = {Charlotte Jee},
  title  = {An Indian politician is using deepfake technology to win new voters},
  year   = {2020},
  month  = {02},
  day    = {19},
  url    = {https://www.technologyreview.com/2020/02/19/868173/an-indian-politician-is-using-deepfakes-to-try-and-win-voters/},
  note   = {Accessed: 10.08.2023}
}

@online{vanity-fair,
  author = {Charlotte Klein},
  title  = {“This Will Be Dangerous in Elections”: Political Media's Next Big Challenge Is Navigating AI Deepfakes},
  year   = {2023},
  month  = {03},
  day    = {06},
  url    = {https://www.vanityfair.com/news/2023/03/ai-2024-deepfake},
  note   = {Accessed: 10.08.2023}
}

@online{politics,
  author = {Kelsey Farish},
  title  = {Political Deepfakes: social media trend or genuine threat?},
  year   = {2022},
  month  = {09},
  day    = {06},
  url    = {https://www.dacbeachcroft.com/en/gb/articles/2022/september/political-deepfakes-social-media-trend-or-genuine-threat/},
  note   = {Accessed: 10.08.2023}
}