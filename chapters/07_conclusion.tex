% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Discussion and Conclusion}\label{chapter:conclusion}
\section{Summary}
In this research, it is demonstrated that the capabilities of deepfakes pose both
opportunities for creative fields, technology advancements and threats to information
integrity. Recognizing the increasing importance of this technology, this thesis analyzes
various detection tools and their ability to counter manipulations. A primary focus is placed
on video detection tools such as Deepware, Seferbekov's and NtechLab's tools. During testing,
it was noted that some tools, despite having good Detection Accuracy and Precision,
had challenges with metrics like Recall and F1-Score. These inconsistencies are
important for various evaluation approaches, considering not just the accuracy but the tool's 
ability to capture true positives.

Moreover, image detection tools, including AI or Not, Illuminarty and Facetorch, were
also observed. While AI or Not and Illuminarty emerged as the more proficient tool,
possibly due to their consistent backing by dedicated companies and communities.
Even though Facetorch showed potential as an open-source project, it fell behind,
unserscoring the importance of regular updates to keep up with the changing landscape
of deepfake techniques.

The research also revealed that not all tools provided clear privacy policies, raising
concerns about user data protection. The relevance of datasets was underscored, with
outdated datasets impacting tool effectiveness.

From the research questions, it was inferred that the effectiveness of deepfake detection
tools is context-specific. The findings suggest that while tools are available, their
efficiency is not guaranteed across all scenarios. This variability in tool performance
has implications for individuals and entities relying on them to detect deepfakes,
emphasizing the need for continuous evaluation and adaptation in tool selection.

\section{Future Work}
There are several applicable areas to focus on for future work. One essential area of
exploration is the expansion of datasets. By testing the tools against diverse and varied
datasets, a broader understanding of the tools can be gained. Moreover, testing with a
larger volume of inputs can offer deeper insights into their scalability, robustness,
and average performance metrics across datasets. Additionally, the need for regular
updates and maintenance cannot be understated. As highlighted by the performance of
tools such as Facetorch, staying updated is crucial to effectively tackle the latest
deepfake generation techniques.

It would be also beneficial to not only keep the
detection tools updated with the latest versions of these algorithms but also to
retrain them periodically with updated techniques. By doing so, these tools can
leverage the most recent advancements in the field. Furthermore, proactive studying of the
latest advancements in deepfake generation tools, allowing researchers to develop detection
methods based on innovations, is crucial to this field.

Most research has focused on spotting changes in videos. But audio manipulation,
like changing voices, isn't studied as much. We need tools that can find both video
and sound changes. Many tools struggle because they're trained with poor or mixed-up
data. New \ac{AI} methods are needed to fix these problems. This shows how complex
deepfake detection is and why we need better solutions.

Considering the increasing concerns around data privacy, it's also suggested that future
studies delve deeper into the privacy policies of deepfake detection tools. It was
observed that not all tools provided clear privacy guidelines, which raises concerns
for users. Ensuring that these tools have transparent privacy policies is essential to
build trust with users. Moreover, understanding how these tools handle and store
user data can provide insights into potential risks. In the future, a more detailed
analysis of these policies, and perhaps even standardization of privacy measures
for such tools, could be beneficial for the community.

\section{Conclusion}
Even though there's extensive research and numerous competitions focused on deepfake
detection, no single method can identify them all. The swift advancements in
deepfake generation could be a reason behind this. Since no approach has consistently
shown to outpace the deepfake generator in effectiveness, it suggests that the world
of deepfakes continues to develop. If it reaches a point where detection tools can't
keep up, distinguishing between authentic and manipulated content might become
nearly impossible. There's also a concern that if deepfake creators use detection
tools as standards, it might unintentionally improve the quality of fake content.
The work documented in this thesis is just a starting point among the countless
opportunities that this field awaits.


From the results shared, individuals seeking to detect deepfakes were subtly shown
that relying solely on a single detection method might be insufficient. The varied
effectiveness of different tools underscored the importance of a broader approach
for more reliable outcomes.
